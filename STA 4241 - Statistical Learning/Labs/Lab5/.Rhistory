ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
# metadata
n = 1:20 * 100 # monotonically increasing dataset size
n.sim = 10 # number of simulations (trials)
model.formula <- Y ~ exp(x = X1) + exp(x = 0.5 * X2)
model.formula.func <- 0
expit = function(x) {
exp(x = x) / (1 + exp(x = x))
}
lda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
qda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
# each simulation or trial
for(i in 1:n.sim) {
# each differently sized dataset per simulation
for(j in 1:length(x = n)) {
# Setup for both LDA and QDA
# generating data
size <- n[j] # size of dataset
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
data$Y = rbinom(n = n, size = 1, p = p)
# train test split
train.index <- caret::createDataPartition(y = data$Y, list = FALSE)
train.set <- data[train.index,]
test.set <- data[-train.index,]
# LDA
# model and prediction
lda.model.prob4 <- MASS::lda(formula = model.formula, data = train.set)
lda.pred.test.prob4 <- as.numeric(x = predict(lda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
# verifying and averaging error rate data over all simulations
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nModel error rates:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.err
qda.err
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nModel error rates means across dataset sizes:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.colMeans <- colMeans(x = lda.err)
qda.colMeans <- colMeans(x = qda.err)
lda.colMeans
qda.colMeans
prob4.err <- as.data.frame(x = cbind('lda.err.means' = lda.colMeans, 'qda.err.means' = qda.colMeans, 'size' = n))
ggplot(data = prob4.err, aes(x = size)) +
geom_point(aes(y = lda.err.means, color = 'green')) +
geom_point(aes(y = qda.err.means, color = 'blue')) +
geom_smooth(
method = lm,
se = FALSE,
fullrange = TRUE,
aes(y = lda.err.means, color = 'green')) +
geom_smooth(
method = lm,
se = FALSE,
fullrange = TRUE,
aes(y = qda.err.means, color = 'blue')) +
scale_color_manual(labels = c('LDA Error Rate', 'QDA Error Rate'), values = c('green', 'blue'))
prob4.err <- as.data.frame(x = cbind('lda.err.means' = lda.colMeans, 'qda.err.means' = qda.colMeans, 'size' = n))
ggplot(data = prob4.err, aes(x = size)) +
geom_point(aes(y = lda.err.means, color = 'green')) +
geom_point(aes(y = qda.err.means, color = 'blue')) +
geom_smooth(
method = lm,
se = FALSE,
fullrange = TRUE,
aes(y = lda.err.means, color = 'green')) +
geom_smooth(
method = lm,
se = FALSE,
fullrange = TRUE,
aes(y = qda.err.means, color = 'blue')) +
scale_color_manual(labels = c('QDA Error Rate', 'LDA Error Rate'), values = c('green', 'blue'))
# metadata
n = 1:20 * 100 # monotonically increasing dataset size
n.sim = 100 # number of simulations (trials)
model.formula <- Y ~ exp(x = X1) + exp(x = 0.5 * X2)
model.formula.func <- 0
expit = function(x) {
exp(x = x) / (1 + exp(x = x))
}
lda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
qda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
# each simulation or trial
for(i in 1:n.sim) {
# each differently sized dataset per simulation
for(j in 1:length(x = n)) {
# Setup for both LDA and QDA
# generating data
size <- n[j] # size of dataset
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
data$Y = rbinom(n = n, size = 1, p = p)
# train test split
train.index <- caret::createDataPartition(y = data$Y, list = FALSE)
train.set <- data[train.index,]
test.set <- data[-train.index,]
# LDA
# model and prediction
lda.model.prob4 <- MASS::lda(formula = model.formula, data = train.set)
lda.pred.test.prob4 <- as.numeric(x = predict(lda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
# verifying and averaging error rate data over all simulations
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nModel error rates:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.err
qda.err
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nModel error rates means across dataset sizes:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.colMeans <- colMeans(x = lda.err)
qda.colMeans <- colMeans(x = qda.err)
lda.colMeans
qda.colMeans
as.data.frame(x = lda.err)
as.dataframe(x = qda.err)
as.data.frame(x = qda.err)
as.data.frame(x = lda.colMeans)
prob4.err <- as.data.frame(x = cbind('lda.err.means' = lda.colMeans, 'qda.err.means' = qda.colMeans, 'size' = n))
prob4.err
ggplot(data = prob4.err, aes(x = size)) +
geom_point(aes(y = lda.err.means, color = 'green')) +
geom_point(aes(y = qda.err.means, color = 'blue')) +
geom_smooth(
method = lm,
se = FALSE,
fullrange = TRUE,
aes(y = lda.err.means, color = 'green')) +
geom_smooth(
method = lm,
se = FALSE,
fullrange = TRUE,
aes(y = qda.err.means, color = 'blue')) +
scale_color_manual(labels = c('QDA Error Rate', 'LDA Error Rate'), values = c('green', 'blue'))
# loading data
prob3 <- read.csv(file = 'data/Problem3.csv')
prob3
# creating models
lda.model.prob3 <- lda(formula = Y ~ X1 + X2, data = prob3)
qda.model.prob3 <- qda(formula = Y ~ X1 + X2, data = prob3)
# printing model objects
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nlda.model.prob3:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.model.prob3
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nqda.model.prob3:\n')
cat('\n', rep(x = '-', times = 20), '\n')
qda.model.prob3
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nLDA:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = lda.model.prob3)
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nQDA:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = qda.model.prob3)
lda.pred.prob3 <- as.numeric(x = predict(lda.model.prob3, grid)$class) - 1
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA')
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nLDA:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = lda.model.prob3)
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nQDA:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = qda.model.prob3)
lda.pred.prob3 <- as.numeric(x = predict(lda.model.prob3, grid)$class) - 1
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA')
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
scale_color_manual(label = 'sdff')
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
guides(fill=guide_legend(title="New Legend Title"))
plt <-
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
guides(fill=guide_legend(title="New Legend Title"))
plt <-
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
plt <- plt + guides(fill=guide_legend(title="New Legend Title"))
plt <-
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA')
plt <- plt + guides(fill=guide_legend(title="New Legend Title"))
plt
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
labs(title = 'sdfd')
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
labs(fill = 'Class')
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
scale_fill_manual('Class')
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
scale_fill_manual('Class', values = c('red', 'yellow', 'green', 'blue'))
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
scale_fill_manual(label = 'Class', values = c('red', 'yellow', 'green', 'blue'))
lda.pred.prob3 <- as.numeric(x = predict(lda.model.prob3, grid)$class) - 1
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA')
# assess the accuracy of the prediction
lda.pred.test.prob3 <- as.numeric(x = predict(lda.model.prob3, prob3.test)$class) - 1
length(x = lda.pred.test.prob3)
# analysis
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nConfusion Matrix:\n')
cat('\n', rep(x = '-', times = 20), '\n')
ct <- table(prob3.test$Y, lda.pred.test.prob3)
ct
cm <- confusionMatrix(data = factor(lda.pred.test.prob3), reference = factor(prob3.test$Y))
cm
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nDiagonal (Correct Predictions):\n')
cat('\n', rep(x = '-', times = 20), '\n')
diag(prop.table(ct, 1))
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nAccuracy and Error Rate:\n')
cat('\n', rep(x = '-', times = 20), '\n')
acc.prob3 <- sum(diag(prop.table(ct)))
err.prob3 <- 1 - sum(diag(prop.table(ct)))
acc.prob3
err.prob3
# assess the accuracy of the prediction
qda.pred.test.prob3 <- as.numeric(x = predict(qda.model.prob3, prob3.test)$class) - 1
length(x = qda.pred.test.prob3)
# assess
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nConfusion Matrix:\n')
cat('\n', rep(x = '-', times = 20), '\n')
ct <- table(prob3.test$Y, qda.pred.test.prob3)
ct
cm.prob3 <- confusionMatrix(data = factor(qda.pred.test.prob3), reference = factor(prob3.test$Y))
cm.prob3
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nDiagonal (Correct Predictions):\n')
cat('\n', rep(x = '-', times = 20), '\n')
diag(prop.table(ct, 1))
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nAccuracy and Error Rate:\n')
cat('\n', rep(x = '-', times = 20), '\n')
acc.prob3 <- sum(diag(prop.table(ct)))
err.prob3 <- 1 - sum(diag(prop.table(ct)))
acc.prob3
err.prob3
prob3.test
length(x = prob3.test[Y == 0, ]
length(x = prob3.test[Y == 0, ])
length(x = prob3.test[Y = 0, ])
length(x = prob3.test['Y' = 0, ])
length(x = prob3.test$Y == 0, ])
prob3.test$Y == 0, ]
prob3.test$Y == 0]
prob3.test$Y > 0
prob3.test$Y == 0
prob3.test[prob3.test$Y == 0, ]
length(x = prob3.test[prob3.test$Y == 0, ])
length(x = prob3.test[prob3.test$Y == 0, ]$Y)
# class sizes
for (class in 0:3)
# class sizes
for (class in 0:3)
# class sizes
for (class in 0:3) {
print(length(x = prob3.test[prob3.test$Y == 0, ]$Y))
}
print(length(x = prob3.test[prob3.test$Y == class, ]$Y))
# class sizes
for (class in 0:3) {
cat('\nClass ', class, ' size: ', length(x = prob3.test[prob3.test$Y == class, ]$Y), '\n')
}
library(dplyr)
prob3.test %>% group_by('Y')
prob3.test %>% group_by(Y)
prob3.test %>% group_by(Y) %>% aggregate(x = Y)
aggregate(x = prob3.test, by = Y)
aggregate(x = prob3.test, by = Y, FUN = mean)
aggregate(x = prob3.test, by = 'Y', FUN = mean)
aggregate(x = prob3.test, by = list('Y'), FUN = mean)
aggregate(x = prob3.test, by = list(c('Y')), FUN = mean)
aggregate(x = prob3.test, by = as.list(x = 'Y'), FUN = mean)
aggregate(x = prob3.test, by = as.list(x = c('Y')), FUN = mean)
aggregate(x = prob3.test, by = as.list(x = prob3.test$Y), FUN = mean)
aggregate(x = prob3.test, by = list(x = prob3.test$Y), FUN = mean)
aggregate(x = prob3.test, by = list(x = prob3.test$Y), FUN = count)
aggregate(x = prob3.test, by = list(x = prob3.test$Y), FUN = n)
prob3.test %>% count(Y)
aggregate(x = prob3.test, by = list(x = prob3.test$Y), FUN = length)
prob3.test %>% count(Y)
class.size <- prob3.test %>% count(Y)
prop.table(x = class.size)
class.size$prop <- prop.table(x = class.size)
class.size$err <- 1 - class.size$prop
class.size
class.size <- prob3.test %>% count(Y)
class.size$prop <- prop.table(x = class.size)
class.size$err <- 1 - class.size$prop
class.size
class.size$prop <- prop.table(x = class.size)$n
class.size
class.size$err <- 1 - class.size$prop
class.size
prob2
prob2 %>% transform(X1^2)
prob2 %>% mutate(X1.squared = X1^2)
prob2$X1.squared = X1^2
prob2$X1.squared <- prob2$X1^2
prob2
prob2$X2.squared <- prob2$X2^2
prob2
# loading data
prob2 <- read.csv(file = 'data/Problem2.csv')
# squaring covariates
prob2$X1.squared <- prob2$X1^2
prob2$X2.squared <- prob2$X2^2
prob2
# creating models
logistic.linear <- glm(formula = Y ~ X1 + X2, data = prob2, family = binomial)
logistic.squared <- glm(formula = Y ~ X1.squared + X2.squared, data = prob2, family = binomial)
lda.model <- lda(formula = Y ~ X1 + X2, data = prob2)
qda.model <- qda(formula = Y ~ X1 + X2, data = prob2)
# printing model objects
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nlogistic.linear:\n')
cat('\n', rep(x = '-', times = 20), '\n')
logistic.linear
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nlogistic.squared:\n')
cat('\n', rep(x = '-', times = 20), '\n')
logistic.squared
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nlda.model:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.model
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nqda.model:\n')
cat('\n', rep(x = '-', times = 20), '\n')
qda.model
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nLogistic regression with linear covariates:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = logistic.linear)
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nLogistic regression with squared covariates:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = logistic.squared)
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nLDA:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = lda.model)
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nQDA:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = qda.model)
# spacing
linspace_num <- seq(-3, 3, 0.1)
ticks <- seq(-3, 3, 0.5)
grid <- expand.grid(X1 = linspace_num, X2 = linspace_num)
logistic.linear.pred <- 1 * (predict(logistic.linear, grid, type = 'response') > 0.5)
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(logistic.linear.pred))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'Logistic Regression (Linear Covariates)') +
scale_color_manual(values = c('green', 'blue'), guide = 'none')
logistic.squared.pred <- 1 * (predict(logistic.squared, grid, type = 'response') > 0.5)
logistic.squared.pred <- 1 * (predict(logistic.squared, grid, type = 'response') > 0.5)
logistic.squared <- glm(formula = Y ~ X1.squared + X2.squared, data = prob2, family = binomial)
logistic.squared.pred <- 1 * (predict(logistic.squared, grid, type = 'response') > 0.5)
logistic.squared.pred <- 1 * (predict(logistic.squared, grid, type = 'response') > 0.5)
logistic.squared.pred <- 1 * (predict(logistic.linear, grid, type = 'response') > 0.5)
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(logistic.squared.pred))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'Logistic Regression (Squared Covariates)') +
scale_color_manual(values = c('green', 'blue'), guide = 'none')
logistic.squared.pred <- 1 * (predict(logistic.squared, grid, type = 'response') > 0.5)
prob3
prob2
logistic.squared.pred <- 1 * (predict(logistic.squared, grid, type = 'response') > 0.5)
logistic.squared.pred <- 1 * (predict(glm(formula = Y ~ X1.squared + X2.squared, data = prob2, family = binomial), grid, type = 'response') > 0.5) - 1
logistic.squared.pred <- 1 * (predict(glm(formula = Y ~ X1.squared + X2.squared, data = prob2, family = binomial), grid, type = 'response') > 0.5) - 1
prob2
logistic.squared.pred <- 1 * (predict(glm(formula = Y ~ X1 + X2, data = prob2, family = binomial), grid, type = 'response') > 0.5) - 1
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(logistic.squared.pred))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'Logistic Regression (Squared Covariates)') +
scale_color_manual(values = c('green', 'blue'), guide = 'none')
logistic.squared.pred <- 1 * (predict(glm(formula = Y ~ X1**2 + X2**2, data = prob2, family = binomial), grid, type = 'response') > 0.5) - 1
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(logistic.squared.pred))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'Logistic Regression (Squared Covariates)') +
scale_color_manual(values = c('green', 'blue'), guide = 'none')
logistic.squared.pred <- 1 * (predict(glm(formula = Y ~ I(X1^2) + I(X2^2), data = prob2, family = binomial), grid, type = 'response') > 0.5) - 1
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(logistic.squared.pred))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'Logistic Regression (Squared Covariates)') +
scale_color_manual(values = c('green', 'blue'), guide = 'none')
lda.pred <- as.numeric(x = predict(lda.model, grid)$class) - 1
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA') +
scale_color_manual(values = c('green', 'blue'), guide = 'none')
qda.pred <- as.numeric(x = predict(qda.model, grid)$class)
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(qda.pred))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'QDA') +
scale_color_manual(values = c('green', 'blue'), guide = 'none')
# assess the accuracy of the prediction
lda.pred.test.prob2 <- as.numeric(x = predict(lda.model.prob2, prob2.test)$class) - 1
