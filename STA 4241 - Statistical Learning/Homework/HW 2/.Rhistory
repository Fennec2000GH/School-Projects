}
print(err.rate.func(model = logistic.linear, data_test = prob2.test))
err.rate.func <- function(model, data_test) {
pred <- 1 * (predict(model,data_test, type = 'response') > 0.5) - 1
ct  <- table(data_test$Y, pred)
1 - sum(diag(prop.table(ct)))
}
print(err.rate.func(model = logistic.linear, data_test = prob2.test)
print(err.rate.func(model = logistic.linear, data_test = prob2.test))
err.rate.func <- function(model, data_test) {
pred <- 1 * (predict(model,data_test, type = 'response') > 0.5) - 1
ct  <- table(data_test$Y, pred)
1 - sum(diag(prop.table(ct)))
}
print(err.rate.func(model = logistic.linear, data_test = prob2.test))
print(err.rate.func(model = qda.model, data_test = prob2.test))
err.rate.logistic.func <- function(model, data_test) {
pred <- 1 * (predict(model,data_test, type = 'response') > 0.5) - 1
ct  <- table(data_test$Y, pred)
1 - sum(diag(prop.table(ct)))
}
err.rate.discriminant.func <- function(model, data_test) {
pred <- as.numeric(predict(model,data_test)$class) - 1
ct  <- table(data_test$Y, pred)
1 - sum(diag(prop.table(ct)))
}
print(err.rate.logistic.func(model = qda.model, data_test = prob2.test))
print(err.rate.logistic.func(model = logistic.linear, data_test = prob2.test))
err.rate.logistic.func <- function(model, data_test) {
pred <- 1 * (predict(model,data_test, type = 'response') > 0.5) - 1
ct  <- table(data_test$Y, pred)
1 - sum(diag(prop.table(ct)))
}
err.rate.discriminant.func <- function(model, data_test) {
pred <- as.numeric(predict(model,data_test)$class) - 1
ct  <- table(data_test$Y, pred)
1 - sum(diag(prop.table(ct)))
}
cat('\nError rates per model:\n')
print(err.rate.logistic.func(model = logistic.linear, data_test = prob2.test))
print(err.rate.logistic.func(model = logistic.squared, data_test = prob2.test))
print(err.rate.logistic.func(model = glm(formula = Y ~ I(X1^2) + I(X2^2), data = prob2, family = binomial), data_test = prob2.test))
err.rate.logistic.func <- function(model, data_test) {
pred <- 1 * (predict(model,data_test, type = 'response') > 0.5) - 1
ct  <- table(data_test$Y, pred)
1 - sum(diag(prop.table(ct)))
}
err.rate.discriminant.func <- function(model, data_test) {
pred <- as.numeric(predict(model,data_test)$class) - 1
ct  <- table(data_test$Y, pred)
1 - sum(diag(prop.table(ct)))
}
cat('\nError rates per model:\n')
print(err.rate.logistic.func(model = logistic.linear, data_test = prob2.test))
print(err.rate.logistic.func(model = glm(formula = Y ~ I(X1^2) + I(X2^2), data = prob2, family = binomial), data_test = prob2.test))
print(err.rate.discriminant.func(model = lda.model, data_test = prob2.test))
print(err.rate.discriminant.func(model = qda.model, data_test = prob2.test))
# loading data
prob3 <- read.csv(file = 'data/Problem3.csv')
prob3
# creating models
lda.model.prob3 <- lda(formula = Y ~ X1 + X2, data = prob3)
qda.model.prob3 <- qda(formula = Y ~ X1 + X2, data = prob3)
# printing model objects
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nlda.model.prob3:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.model.prob3
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nqda.model.prob3:\n')
cat('\n', rep(x = '-', times = 20), '\n')
qda.model.prob3
# loading data
prob3 <- read.csv(file = 'data/Problem3.csv')
prob3
# creating models
lda.model.prob3 <- lda(formula = Y ~ X1 + X2, data = prob3)
qda.model.prob3 <- qda(formula = Y ~ X1 + X2, data = prob3)
# printing model objects
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nlda.model.prob3:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.model.prob3
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nqda.model.prob3:\n')
cat('\n', rep(x = '-', times = 20), '\n')
qda.model.prob3
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nLDA:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = lda.model.prob3)
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nQDA:\n')
cat('\n', rep(x = '-', times = 20), '\n')
summary(object = qda.model.prob3)
lda.pred.prob3 <- as.numeric(x = predict(lda.model.prob3, grid)$class) - 1
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = lda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'LDA')
qda.pred.prob3 <- as.numeric(x = predict(qda.model.prob3, grid)$class) - 1
ggplot(data = grid, aes(x = X1, y = X2, color = as.factor(x = qda.pred.prob3))) +
geom_point() +
scale_x_continuous(breaks = ticks) +
scale_y_continuous(breaks = ticks) +
ggtitle(label = 'QDA')
# load test dataset
prob3.test <- read.csv(file = 'data/Problem3test.csv')
prob3.test
# assess the accuracy of the prediction
lda.pred.test.prob3 <- as.numeric(x = predict(lda.model.prob3, prob3.test)$class) - 1
length(x = lda.pred.test.prob3)
# analysis
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nConfusion Matrix:\n')
cat('\n', rep(x = '-', times = 20), '\n')
ct <- table(prob3.test$Y, lda.pred.test.prob3)
ct
cm <- confusionMatrix(data = factor(lda.pred.test.prob3), reference = factor(prob3.test$Y))
cm
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nDiagonal (Correct Predictions):\n')
cat('\n', rep(x = '-', times = 20), '\n')
diag(prop.table(ct, 1))
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nAccuracy and Error Rate:\n')
cat('\n', rep(x = '-', times = 20), '\n')
acc.prob3 <- sum(diag(prop.table(ct)))
err.prob3 <- 1 - sum(diag(prop.table(ct)))
acc.prob3
err.prob3
# assess the accuracy of the prediction
qda.pred.test.prob3 <- as.numeric(x = predict(qda.model.prob3, prob3.test)$class) - 1
length(x = qda.pred.test.prob3)
# assess
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nConfusion Matrix:\n')
cat('\n', rep(x = '-', times = 20), '\n')
ct <- table(prob3.test$Y, qda.pred.test.prob3)
ct
cm.prob3 <- confusionMatrix(data = factor(qda.pred.test.prob3), reference = factor(prob3.test$Y))
cm.prob3
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nDiagonal (Correct Predictions):\n')
cat('\n', rep(x = '-', times = 20), '\n')
diag(prop.table(ct, 1))
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nAccuracy and Error Rate:\n')
cat('\n', rep(x = '-', times = 20), '\n')
acc.prob3 <- sum(diag(prop.table(ct)))
err.prob3 <- 1 - sum(diag(prop.table(ct)))
acc.prob3
err.prob3
# class sizes
for (class in 0:3) {
cat('\nClass ', class, ' size: ', length(x = prob3.test[prob3.test$Y == class, ]$Y), '\n')
}
class.size <- prob3.test %>% count(Y)
# class sizes
for (class in 0:3) {
cat('\nClass ', class, ' size: ', length(x = prob3.test[prob3.test$Y == class, ]$Y), '\n')
}
class.size <- prob3.test %>% count(Y)
class.size <- prob3.test %>% count(Y)
prob3.test
class.size <- prob3.test %>% n(Y)
library(dplyr)
class.size <- prob3.test %>% count(Y)
# class sizes
for (class in 0:3) {
cat('\nClass ', class, ' size: ', length(x = prob3.test[prob3.test$Y == class, ]$Y), '\n')
}
library(dplyr)
class.size <- prob3.test %>% count(Y)
class.size$prop <- prop.table(x = class.size)$n
class.size$err <- 1 - class.size$prop
class.size
# metadata
n = 1:20 * 100 # monotonically increasing dataset size
n.sim = 100 # number of simulations (trials)
model.formula <- Y ~ exp(x = X1) + exp(x = 0.5 * X2)
model.formula.func <- 0
expit = function(x) {
exp(x = x) / (1 + exp(x = x))
}
lda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
qda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
# each simulation or trial
for(i in 1:n.sim) {
# each differently sized dataset per simulation
for(j in 1:length(x = n)) {
# Setup for both LDA and QDA
# generating data
size <- n[j] # size of dataset
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
data$Y = rbinom(n = n, size = 1, p = p)
# train test split
train.index <- caret::createDataPartition(y = data$Y, list = FALSE)
train.set <- data[train.index,]
test.set <- data[-train.index,]
# LDA
# model and prediction
lda.model.prob4 <- MASS::lda(formula = model.formula, data = train.set)
lda.pred.test.prob4 <- as.numeric(x = predict(lda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
# verifying and averaging error rate data over all simulations
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nModel error rates:\n')
cat('\n', rep(x = '-', times = 20), '\n')
as.data.frame(x = lda.err)
as.data.frame(x = qda.err)
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nModel error rates means across dataset sizes:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.colMeans <- colMeans(x = lda.err)
qda.colMeans <- colMeans(x = qda.err)
prob4.err <- as.data.frame(x = cbind('lda.err.means' = lda.colMeans, 'qda.err.means' = qda.colMeans, 'size' = n))
prob4.err
n.sim = 100 # number of simulations (trials)
# each simulation or trial
for(i in 1:n.sim) {
# each differently sized dataset per simulation
for(j in 1:length(x = n)) {
# Setup for both LDA and QDA
# generating data
size <- n[j] # size of dataset
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
data$Y = rbinom(n = n, size = 1, p = p)
# train test split
train.index <- caret::createDataPartition(y = data$Y, list = FALSE)
train.set <- data[train.index,]
test.set <- data[-train.index,]
# LDA
# model and prediction
lda.model.prob4 <- MASS::lda(formula = model.formula, data = train.set)
lda.pred.test.prob4 <- as.numeric(x = predict(lda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
lda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
qda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
# each simulation or trial
for(i in 1:n.sim) {
# each differently sized dataset per simulation
for(j in 1:length(x = n)) {
# Setup for both LDA and QDA
# generating data
size <- n[j] # size of dataset
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
data$Y = rbinom(n = n, size = 1, p = p)
# train test split
train.index <- caret::createDataPartition(y = data$Y, list = FALSE)
train.set <- data[train.index,]
test.set <- data[-train.index,]
# LDA
# model and prediction
lda.model.prob4 <- MASS::lda(formula = model.formula, data = train.set)
lda.pred.test.prob4 <- as.numeric(x = predict(lda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
# metadata
n = 1:20 * 100 # monotonically increasing dataset size
n.sim = 100 # number of simulations (trials)
model.formula <- Y ~ exp(x = X1) + exp(x = 0.5 * X2)
model.formula.func <- 0
expit = function(x) {
exp(x = x) / (1 + exp(x = x))
}
lda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
qda.err <- matrix(data = 0, nrow = n.sim, ncol = length(x = n))
# each simulation or trial
for(i in 1:n.sim) {
}
# each simulation or trial
for(i in 1:n.sim) {
print(i)
}
# each simulation or trial
for(i in 1:n.sim) {
# each differently sized dataset per simulation
for(j in 1:length(x = n)) {
print(j)
# Setup for both LDA and QDA
# generating data
size <- n[j] # size of dataset
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
data$Y = rbinom(n = n, size = 1, p = p)
# train test split
train.index <- caret::createDataPartition(y = data$Y, list = FALSE)
train.set <- data[train.index,]
test.set <- data[-train.index,]
# LDA
# model and prediction
lda.model.prob4 <- MASS::lda(formula = model.formula, data = train.set)
lda.pred.test.prob4 <- as.numeric(x = predict(lda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
# each simulation or trial
for(i in 1:n.sim) {
# each differently sized dataset per simulation
for(j in 1:length(x = n)) {
cat('\nj = ', j, '\n')
# Setup for both LDA and QDA
# generating data
size <- n[j] # size of dataset
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
data$Y = rbinom(n = n, size = 1, p = p)
# train test split
train.index <- caret::createDataPartition(y = data$Y, list = FALSE)
train.set <- data[train.index,]
test.set <- data[-train.index,]
# LDA
# model and prediction
lda.model.prob4 <- MASS::lda(formula = model.formula, data = train.set)
lda.pred.test.prob4 <- as.numeric(x = predict(lda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
# each simulation or trial
for(i in 1:n.sim) {
# each differently sized dataset per simulation
for(j in 1:length(x = n)) {
cat('\nj = ', j, '\n')
# Setup for both LDA and QDA
# generating data
size <- n[j] # size of dataset
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
data$Y = rbinom(n = n, size = 1, p = p)
print(length(data))
# train test split
train.index <- caret::createDataPartition(y = data$Y, list = FALSE)
train.set <- data[train.index,]
test.set <- data[-train.index,]
# LDA
# model and prediction
lda.model.prob4 <- MASS::lda(formula = model.formula, data = train.set)
lda.pred.test.prob4 <- as.numeric(x = predict(lda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
n
data
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data$Y = rbinom(n = n, size = 1, p = p)
print(length(data))
# each simulation or trial
for(i in 1:n.sim) {
# each differently sized dataset per simulation
for(j in 1:length(x = n)) {
# cat('\nj = ', j, '\n')
# Setup for both LDA and QDA
# generating data
size <- n[j] # size of dataset
data <- data.frame(X1 = rnorm(n = size), X2 = rnorm(n = size))
p <- expit(x = exp(data$X1) - exp(0.5 * data$X2))
data$Y = rbinom(n = n, size = 1, p = p)
# train test split
train.index <- caret::createDataPartition(y = data$Y, list = FALSE)
train.set <- data[train.index,]
test.set <- data[-train.index,]
# LDA
# model and prediction
lda.model.prob4 <- MASS::lda(formula = model.formula, data = train.set)
lda.pred.test.prob4 <- as.numeric(x = predict(lda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, lda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
lda.err[i, j] <- err.prob4
# QDA
# model and prediction
qda.model.prob4 <- MASS::qda(formula = model.formula, data = train.set)
qda.pred.test.prob4 <- as.numeric(x = predict(qda.model.prob4, test.set)$class) - 1
# evaluation
ct <- table(test.set$Y, qda.pred.test.prob4)
acc.prob4 <- sum(diag(prop.table(ct)))
err.prob4 <- 1 - sum(diag(prop.table(ct)))
qda.err[i, j] <- err.prob4
}
}
# verifying and averaging error rate data over all simulations
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nModel error rates:\n')
cat('\n', rep(x = '-', times = 20), '\n')
as.data.frame(x = lda.err)
as.data.frame(x = qda.err)
cat('\n', rep(x = '-', times = 20), '\n')
cat('\nModel error rates means across dataset sizes:\n')
cat('\n', rep(x = '-', times = 20), '\n')
lda.colMeans <- colMeans(x = lda.err)
qda.colMeans <- colMeans(x = qda.err)
prob4.err <- as.data.frame(x = cbind('lda.err.means' = lda.colMeans, 'qda.err.means' = qda.colMeans, 'size' = n))
prob4.err
ggplot(data = prob4.err, aes(x = size)) +
geom_point(aes(y = lda.err.means, color = 'green')) +
geom_point(aes(y = qda.err.means, color = 'blue')) +
geom_smooth(
method = lm,
se = FALSE,
fullrange = TRUE,
aes(y = lda.err.means, color = 'green')) +
geom_smooth(
method = lm,
se = FALSE,
fullrange = TRUE,
aes(y = qda.err.means, color = 'blue')) +
scale_color_manual(labels = c('QDA Error Rate', 'LDA Error Rate'), values = c('green', 'blue'))
install.packages(packages)
install.packages(packages)
packages <- c('caret', 'ggplot2', 'MASS', 'plyr', 'purrr')
install.packages(packages)
lapply(X = packages, FUN = library, character.only = TRUE)
install.packages(packages)
packages <- c('caret', 'ggplot2', 'MASS', 'plyr')
install.packages(packages)
install.packages(packages)
options(repos = list(CRAN="http://cran.rstudio.com/"))
options(repos = list(CRAN="http://cran.rstudio.com/"))
packages <- c('caret', 'ggplot2', 'MASS', 'plyr')
install.packages(packages)
lapply(X = packages, FUN = library, character.only = TRUE)
install.packages(packages)
