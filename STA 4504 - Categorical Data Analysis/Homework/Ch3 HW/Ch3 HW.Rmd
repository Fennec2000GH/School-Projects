---
title: "Ch3 HW"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Install packages.
```{r echo = TRUE}

packages <- c('AER', 'DHARMa', 'dplyr', 'ggplot2', 'lmtest', 'MASS')
install.packages(packages)
lapply(packages, library, character.only = TRUE)

```

Question 6 Setup

```{r pressure, echo=FALSE}

y <- c(5,18,19,25,7,7,2); n <- c(6,21,20,36,17,18,3)
x <- c(1,2,3,4,5,6,7)
fit <- glm(y/n ~ x, family=binomial(link=logit), weights=n)
summary(fit)
confint(fit)

```
```{r echo = TRUE}

fit_summary <- summary(fit)
fit_estimates <- as.data.frame(fit_summary$coefficients)

fit_summary
fit_estimates

```

Question 6b

```{r, echo = TRUE}

span <- 1.96 * 0.1564
c( -0.5901 - span,  -0.5901  + span) 

```

Question 6c
Two ways of doing Wald test statistic.

```{r, echo = TRUE}

# Computing Wald test statistic
b_estimate <- fit_estimates['x', 'Estimate']
se <- fit_estimates['x', 'Std. Error']
wald_test_statistic <- b_estimate / se

cat('\nbeta hat: ', b_estimate)
cat('\nse: ', se)
cat('\nWald test statistic: ', wald_test_statistic)

# Assuming the reduced model (intercept) uses only 1 less variable than full model
cat('\np-value: ', pchisq(q = wald_test_statistic^2, df = 1, lower.tail = FALSE))

```

```{r, echo = TRUE}

waldtest(fit)

```
Question 6d
Two different ways for LRT.

```{r, echo = TRUE}

drop1(fit, test = 'LRT')

```
```{r, echo = TRUE}

model0 <- glm(y/n ~ 1, family=binomial(link=logit), weights=n)
model1 <- glm(y/n ~ x, family=binomial(link=logit), weights=n)
lrtest(model0, model1)

```

Mini Project

```{r, echo = TRUE}
## Create a dataset manually
nonmel <- read.table(header = TRUE,
                     text = "
   cases city u1 u2 u3 u4 u5 u6 u7      n
1      1    0  1  0  0  0  0  0  0 172675
2     16    0  0  1  0  0  0  0  0 123065
3     30    0  0  0  1  0  0  0  0  96216
4     71    0  0  0  0  1  0  0  0  92051
5    102    0  0  0  0  0  1  0  0  72159
6    130    0  0  0  0  0  0  1  0  54722
7    133    0  0  0  0  0  0  0  1  32185
8     40    0  0  0  0  0  0  0  0   8328
9      4    1  1  0  0  0  0  0  0 181343
10    38    1  0  1  0  0  0  0  0 146207
11   119    1  0  0  1  0  0  0  0 121374
12   221    1  0  0  0  1  0  0  0 111353
13   259    1  0  0  0  0  1  0  0  83004
14   310    1  0  0  0  0  0  1  0  55932
15   226    1  0  0  0  0  0  0  1  29007
16    65    1  0  0  0  0  0  0  0   7583
")

## Create age.range variable and city variable
nonmel <- within(nonmel, {
    age.range <- rep(c("15_24","25_34","35_44","45_54","55_64","65_74","75_84","85+"), 2)
    age.range <- factor(age.range)
    age.range <- relevel(age.range, ref = "85+")

    city <- factor(city, 0:1, c("Minneapolis", "Dallas"))
})

## rop unnecessary columns
nonmel <- nonmel[c("cases","n","city","age.range")]

## Check data
nonmel

```

```{r, echo = TRUE}

# df (DataFrame) will be used from now on, since it contains all necessary data
df <- as.data.frame(x = aggregate(formula = cbind(cases,  n) ~ age.range, data = nonmel, FUN = sum))
age.midpoints <- c(85.0, 19.5, 29.5, 39.5, 49.5, 59.5, 69.5, 79.5)
df <- cbind(df, age.midpoints)
df

ggplot(data = df) + geom_point() + aes(x = age.midpoints, y = cases / n)

```

Fitting GLMs.
Let `m0_*` and `m1_*` be the reduced model and full models, respectively. The `*` is simply a placeholder for the type of random component.

```{r, echo = TRUE}

# Random component is poisson
m0_poisson <- glm(formula = cases ~ 1, data = df, family = poisson(link = 'log'), weights = n)
m1_poisson <- glm(formula = cases ~ age.midpoints, data = df, family = poisson(link = 'log'), weights = n)

summary(object = m0_poisson)
summary(object = m1_poisson)

```

```{r, echo = TRUE}

# Random component is binomial
m0_binomial <- glm(formula = cases / n ~ 1, data = df, family = binomial(link = 'logit'))
m1_binomial <- glm(formula = cases / n ~ age.midpoints, data = df, family = binomial(link = 'logit'))

summary(object = m0_binomial)
summary(object = m1_binomial)

```

Hypothesis testing.

H0: Parameter for `age.range` is zero (0), meaning `m0 ~ m1`.


```{r, echo = TRUE}

waldtest(m0_poisson, m1_poisson)
lrtest(m0_poisson, m1_poisson)

```
Check for overdispersion, which is confirmed via different methods below.

```{r, echo = TRUE}

wald_stat <- m1_poisson$coefficients['age.midpoints'] / as.data.frame(x = summary(m1_poisson)$coefficients)['age.midpoints', 'Std. Error']

pchisq(q = wald_stat^2, df = 1, lower.tail = FALSE)
sum(residuals(object = m1_poisson, type ="pearson")^2) / m1_poisson$df.residual

# With AER
dispersiontest(object = m1_poisson)

# With DHARMa
sim_m1_poisson <- simulateResiduals(m1_poisson) 
testOverdispersion(sim_m1_poisson)

```

Fixing overdispersion in GLM.

```{r, echo = TRUE}

# Quasipoisson 
qpoi_mod = glm(formula = cases ~ age.midpoints, family = quasipoisson, data = df, weights = n)
summary(qpoi_mod)
sum(residuals(object = qpoi_mod, type ="pearson")^2) / qpoi_mod$df.residual

# Negative binomial
nb_mod = glm.nb(formula = cases ~ age.midpoints, data = df, weights = n)
summary(nb_mod)
sum(residuals(object = nb_mod, type ="pearson")^2) / nb_mod$df.residual

```

Residuals.

```{r, echo = TRUE}

plot(m1_poisson)

```


```{r, echo = TRUE}

plot(m1_binomial)

```

