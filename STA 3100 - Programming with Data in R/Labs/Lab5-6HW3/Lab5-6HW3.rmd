---
title: "Lab5-6HW3"
author: "Caijun Qin"
date: "3/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Foundations for statistical inference - Sampling distributions

In this lab, we investigate the ways in which the statistics from a random sample of data can serve as point estimates for population parameters. We're interested in formulating a sampling distribution of our estimate in order to learn about the properties of the estimate, such as its distribution.

## The data

We consider real estate data from the city of Ames, Iowa. The details of every real estate transaction in Ames is recorded by the City Assessor's office. Our particular focus for this lab will be all residential home sales in Ames between 2006 and 2010. This collection represents our population of interest. In this lab we would like to learn about these home sales by taking smaller samples from the full population. Let's load the data.

```{r, echo = TRUE, out.width = '55%'}
download.file("http://www.openintro.org/stat/data/ames.RData", destfile = "ames.RData")
load("ames.RData")

```

We see that there are quite a few variables in the data set, enough to do a very in-depth analysis. For this lab, we'll restrict our attention to just two of the variables: the above ground living area of the house in square feet (Gr.Liv.Area) and the sale price (SalePrice). To save some effort throughout the lab, create two variables with short names that represent these two variables.

```{r, echo = TRUE, out.width = '55%'}
area <- ames$Gr.Liv.Area
price <- ames$SalePrice

```

Let's look at the distribution of area in our population of home sales by calculating a few summary statistics and making a histogram.

```{r, echo = TRUE, out.width = '55%'}
summary(area)
hist(area)
```
# Exercise 1: Describe this population distribution.

Resp: The population distribution follows a slightly right skewed bell curve. The mean and variance defining the distribution are computed below.


```{r, echo = TRUE, out.width = '55%'}

cat("\npopulation mean: ", mean(x = area))
cat("\npopulation variance: ", var(x = area))

```

## The unknown sampling distribution


In this lab we have access to the entire population, but this is rarely the case in real life. Gathering information on an entire population is often extremely costly or impossible. Because of this, we often take a sample of the population and use that to understand the properties of the population.

If we were interested in estimating the mean living area in Ames based on a sample, we can use the following command to survey the population.

```{r, echo = TRUE, out.width = '55%'}

samp1 <- sample(area, 50)

```

# Exercise 2: Describe the distribution of this sample. How does it compare to the distribution of the population?

Resp: The sample distribution based off of `samp1` is a slightly right skewed distribution similar in shape to the distribution based off the population (`area`). The sample mean x̄ = 1338.86 is slightly under the population mean μ =1499.69 , but sample variance s = 142331.9 is much smaller than the population variance σ = 255539.2.

```{r, echo = TRUE, out.width = '55%'}

hist(x = samp1)
cat("\npopulation mean: ", mean(x = area))
cat("\nsamp1 mean: ", mean(x = samp1))
cat("\npopulation variance: ", var(x = area))
cat("\nsamp1 vaiance: ", var(x = samp1))

```

If we're interested in estimating the average living area in homes in Ames using the sample, our best single guess is the sample mean.


```{r, echo = TRUE, out.width = '55%'}

mean(samp1)

```

Depending on which 50 homes you selected, your estimate could be a bit above or a bit below the true population mean of 1499.69 square feet. In general, though, the sample mean turns out to be a pretty good estimate of the average living area, and we were able to get it by sampling less than 3% of the population.

Exercise 3: Take a second sample, also of size 50, and call it samp2. How does the mean of samp2 compare with the mean of samp1? Suppose we took two more samples, one of size 100 and one of size 1000. Which would you think would provide a more accurate estimate of the population mean?

Resp: `samp2` shares a similar shape in frequency distribution as `samp1`. The mean of samp2, 1439.68, is also relatively close to the mean of samp1, 1338.86, considering the massive spread of data in the population. This similarity can be partly attributed to both samples using the same population of data and having the same sample size n = 50. After comparing a sample of size 100  (`samp_100`) against a sample size of 1000 (`samp_1000`), the `samp_1000` more accurately represents the population distribution. While `samp_100` has a mean of 1513.84, `samp_1000` has a mean of 1507.961, closer to the population mean of 1499.69.

```{r, echo = TRUE, out.width = '55%'}

samp2 <- sample(area, 50)

cat("\nsamp1 mean: ", mean(x = samp1))
cat("\nsamp1 vaiance: ", var(x = samp1))
cat("\nsamp1 summary:\n")
summary(object = samp1)
hist(x = samp1)

cat("\nsamp2 mean: ", mean(x = samp2))
cat("\nsamp2 vaiance: ", var(x = samp2))
cat("\nsamp2 summary\n:")
summary(object = samp2)
hist(x = samp2)

samp_100 <- sample(area, 100)
samp_1000 <- sample(area, 1000)
hist(x = samp_100)
hist(x = samp_1000)
cat("\npopulation mean: ", mean(x = area))
cat("\nsamp_100 mean: ", mean(x = samp_100))
cat("\npopulation mean: ", mean(x = samp_1000))

```

Not surprisingly, every time we take another random sample, we get a different sample mean. It's useful to get a sense of just how much variability we should expect when estimating the population mean this way. The distribution of sample means, called the sampling distribution, can help us understand this variability. In this lab, because we have access to the population, we can build up the sampling distribution for the sample mean by repeating the above steps many times. Here we will generate 5000 samples and compute the sample mean of each.

```{r, echo = TRUE, out.width = '55%'}

sample_means50 <- rep(NA, 5000)

for(i in 1:5000){
   samp <- sample(area, 50)
   sample_means50[i] <- mean(samp)
   }

hist(sample_means50)

```
If you would like to adjust the bin width of your histogram to show a little more detail, you can do so by changing the breaks argument.

```{r, echo = TRUE, out.width = '55%'}

hist(sample_means50, breaks = 25)

```

Here we use R to take 5000 samples of size 50 from the population, calculate the mean of each sample, and store each result in a vector called sample_means50. On the next page, we'll review how this set of code works.

Exercise 4: How many elements are there in sample_means50? Describe the sampling distribution, and be sure to specifically note its center. Would you expect the distribution to change if we instead collected 50,000 sample means?

Resp: There are 5000 elements in `sample_means50`. The distribution has a mean of 1498.405. Collecting a large sample, such as with n = 50000, would shrink the variance of the sampling distribution. However, the mean of the sample means would only slightly shift, most likely closer to the population mean μ.

```{r, echo = TRUE, out.width = '55%'}

cat("\nsample_means50: ", mean(x = sample_means50))

```

## Interlude: The for loop
Let's take a break from the statistics for a moment to let that last block of code sink in. You have just run your first for loop, a cornerstone of computer programming. The idea behind the for loop is iteration: it allows you to execute code as many times as you want without having to type out every iteration. In the case above, we wanted to iterate the two lines of code inside the curly braces that take a random sample of size 50 from area then save the mean of that sample into the sample_means50 vector. Without the for loop, this would be painful:

```{r, echo = TRUE, out.width = '55%'}

sample_means50 <- rep(NA, 5000)

samp <- sample(area, 50)
sample_means50[1] <- mean(samp)

samp <- sample(area, 50)
sample_means50[2] <- mean(samp)

samp <- sample(area, 50)
sample_means50[3] <- mean(samp)

samp <- sample(area, 50)
sample_means50[4] <- mean(samp)

```

and so on...

With the for loop, these thousands of lines of code are compressed into a handful of lines. We've added one extra line to the code below, which prints the variable i during each iteration of the for loop. Run this code.

```{r, echo = TRUE, out.width = '55%'}

sample_means50 <- rep(NA, 5000)

for(i in 1:5000){
   samp <- sample(area, 50)
   sample_means50[i] <- mean(samp)
   print(i)
}

```

Let's consider this code line by line to figure out what it does. In the first line we initialized a vector. In this case, we created a vector of 5000 zeros called sample_means50. This vector will will store values generated within the for loop.

The second line calls the for loop itself. The syntax can be loosely read as, "for every element i from 1 to 5000, run the following lines of code". You can think of i as the counter that keeps track of which loop you're on. Therefore, more precisely, the loop will run once when i = 1, then once when i = 2, and so on up to i = 5000.

The body of the for loop is the part inside the curly braces, and this set of code is run for each value of i. Here, on every loop, we take a random sample of size 50 from area, take its mean, and store it as the ith element of sample_means50.

In order to display that this is really happening, we asked R to print i at each iteration. This line of code is optional and is only used for displaying what's going on while the for loop is running.

The for loop allows us to not just run the code 5000 times, but to neatly package the results, element by element, into the empty vector that we initialized at the outset.

Exercise 5: To make sure you understand what you've done in this loop, try running a smaller version. Initialize a vector of 100 zeros called `sample_means_small`. Run a loop that takes a sample of size 50 from area and stores the sample mean in `sample_means_small`, but only iterate from 1 to 100. Print the output to your screen (type sample_means_small into the console and press enter). How many elements are there in this object called sample_means_small? What does each element represent?

Resp: `sample_means_small` has 100 elements. Each element represents the sample mean of a specific sample of size n = 50.

```{r, echo = TRUE, out.width = '55%'}

sample_means_small <- rep(0, 100)

for(i in 1:100) {
  samp <- sample(area, 50)
  sample_means_small[i] <- mean(samp)
}

sample_means_small

```

## Sample size and the sampling distribution
Mechanics aside, let's return to the reason we used a for loop: to compute a sampling distribution, specifically, this one.

```{r, echo = TRUE, out.width = '55%'}

hist(sample_means50)

```

The sampling distribution that we computed tells us much about estimating the average living area in homes in Ames. Because the sample mean is an unbiased estimator, the sampling distribution is centered at the true average living area of the the population, and the spread of the distribution indicates how much variability is induced by sampling only 50 home sales.

To get a sense of the effect that sample size has on our distribution, let's build up two more sampling distributions: one based on a sample size of 10 and another based on a sample size of 100.

```{r, echo = TRUE, out.width = '55%'}

sample_means10 <- rep(NA, 5000)
sample_means100 <- rep(NA, 5000)

for(i in 1:5000){
  samp <- sample(area, 10)
  sample_means10[i] <- mean(samp)
  samp <- sample(area, 100)
  sample_means100[i] <- mean(samp)
}

```

Here we're able to use a single for loop to build two distributions by adding additional lines inside the curly braces. Don't worry about the fact that samp is used for the name of two different objects. In the second command of the for loop, the mean of samp is saved to the relevant place in the vector sample_means10. With the mean saved, we're now free to overwrite the object samp with a new sample, this time of size 100. In general, anytime you create an object using a name that is already in use, the old object will get replaced with the new one.

To see the effect that different sample sizes have on the sampling distribution, plot the three distributions on top of one another.

```{r, echo = TRUE, out.width = '55%'}

par(mfrow = c(3, 1))

xlimits <- range(sample_means10)

hist(sample_means10, breaks = 20, xlim = xlimits)
hist(sample_means50, breaks = 20, xlim = xlimits)
hist(sample_means100, breaks = 20, xlim = xlimits)

```

The first command specifies that you'd like to divide the plotting area into 3 rows and 1 column of plots (to return to the default setting of plotting one at a time, use par(mfrow = c(1, 1))). The breaks argument specifies the number of bins used in constructing the histogram. The xlim argument specifies the range of the x-axis of the histogram, and by setting it equal to xlimits for each histogram, we ensure that all three histograms will be plotted with the same limits on the x-axis.

Exercise 6: When the sample size is larger, what happens to the center? What about the spread?

Resp: As the sample size increases, the center (mean) of the distribution of sample means shifts slightly closer to the population mean. The spread rapidly decreases at a much faster rate of change than the distribution mean.

## On your own

1. Take a random sample of size 50 from price. Using this sample, what is your best point estimate of the population mean?

Resp: The best point estimate of the population mean μ is the sample mean x̄.

```{r, echo = TRUE, out.width = '55%'}

summary(ames$SalePrice)
cat("price data type: ", typeof(ames$SalePrice))

sample_price <- sample(x = ames$SalePrice, size = 50)
cat("\nsample_price:\n")
print(sample_price)

price_mean_pop <- mean(x = ames$SalePrice)
price_mean_sample <- mean(x = sample_price)
cat("\npopulation mean: ", price_mean_pop)
cat("\nsample mean: ", price_mean_sample)

```
2. Since you have access to the population, simulate the sampling distribution for x¯price by taking 5000 samples from the population of size 50 and computing 5000 sample means. Store these means in a vector called sample_means50. Plot the data, then describe the shape of this sampling distribution. Based on this sampling distribution, what would you guess the mean home price of the population to be? Finally, calculate and report the population mean.

Resp: The distribution of the 5000 sample means, where each sample has size n = 50, follows a roughly normal distribution. Theoretically, the expected value of the mean of the sample means is the population mean μ. From repeated execution of the code below, the mean of the histogram plotted seems to be slightly over 180000. Based on the current execution, the mean sales price is predicted to be 180724.5. The actual population mean of sales price is μ = 180796.1.

```{r, echo = TRUE, out.width = '55%'}

sample_means50 <- rep(x = NA, 5000)
for(i in 1:5000) {
  sample50 <- sample(x = ames$SalePrice, size = 50)
  sample50_mean <- mean(x = sample50)
  sample_means50[i] <- sample50_mean
}

cat("\n5000 sample means of sample size 50 (head):\n", head(x = sample_means50))
cat("\nmean of sample mean distribution: ", mean(x = sample_means50))
cat("\nvariance of sample mean distribution: ", var(x = sample_means50))
cat("\npopulation mean: ", mean(x = ames$SalePrice))
hist(x = sample_means50)

```

3. Change your sample size from 50 to 150, then compute the sampling distribution using the same method as above, and store these means in a new vector called sample_means150. Describe the shape of this sampling distribution, and compare it to the sampling distribution for a sample size of 50. Based on this sampling distribution, what would you guess to be the mean sale price of homes in Ames?

Resp: The distribution of 5000 sample means with a sample size n = 150 still has a normal distribution. The mean of the distribution is still slightly over 180000. However, the variance (and standard deviation) of the distribution for n = 150 is much smaller than for n = 50. Specifically, the variance has shrunk from a previous value of about 120 million to about 40 million now. Based on the current execution, the mean sales price is predicted to be 180628.4.

```{r, echo = TRUE, out.width = '55%'}

sample_means150 <- rep(x = NA, 5000)
for(i in 1:5000) {
  sample150 <- sample(x = ames$SalePrice, size = 150)
  sample150_mean <- mean(x = sample150)
  sample_means150[i] <- sample150_mean
}

cat("\n5000 sample means of sample size 150 (head):\n", head(x = sample_means150))
cat("\nmean of sample mean distribution: ", mean(x = sample_means150))
cat("\nvariance of sample mean distribution: ", var(x = sample_means150))
cat("\npopulation mean: ", mean(x = ames$SalePrice))
hist(x = sample_means150)

```

4. Of the sampling distributions from 2 and 3, which has a smaller spread? If we're concerned with making estimates that are more often close to the true value, would we prefer a distribution with a large or small spread?

Resp: Since the distribution in question 3 has a drastically smaller variance (and standard deviation), that same distribution also has smaller spread than in question 2. Estimating the true value of the population mean (or other measures of center) should be done with the distribution with smaller spread. Given the same distance gap centered around a distribution of sample statistics, such as the sample mean, a smaller spread indicates a greater area under the density curve will be covered. This translates to greater probability in capturing the true parameter within that gap.

# Foundations for statistical inference - Confidence Intervals
## The data

In the previous lab, ``Sampling Distributions'', we looked at the population data of houses from Ames, Iowa. Let's start by loading that data set.

```{r, echo = TRUE, out.width = '55%'}

download.file("http://www.openintro.org/stat/data/ames.RData", destfile = "ames.RData")
load("ames.RData")

```
In this lab we'll start with a simple random sample of size 60 from the population. Specifically, this is a simple random sample of size 60. Note that the data set has information on many housing variables, but for the first portion of the lab we'll focus on the size of the house, represented by the variable Gr.Liv.Area.

```{r, echo = TRUE, out.width = '55%'}

population <- ames$Gr.Liv.Area
samp <- sample(population, 60)

```

Exercise 1: Describe the distribution of your sample. What would you say is the "typical" size within your sample? Also state precisely what you interpreted "typical" to mean.

Resp: The distribution of living area from a sample size n = 60 seems to be right-skewed, with the "typical" size of a house between 1000-1500 area sq. ft. There are relatively very few houses with a size > 2000. The word "typical" indicates the sampling distribution mean, which is 1440.717 for the current execution of code. 

```{r, echo = TRUE, out.width = '55%'}

hist(x = samp)
cat("\nmean of sample: ", mean(x = samp))

```

Exercise 2: Would you expect another student's distribution to be identical to yours? Would you expect it to be similar? Why or why not?

Resp: The probability of someone else's sampling, given sampling size n = 60, choosing the exact same data points as mine would be extrmely small. Since sampling is done without replacement, there are m = 2930! / ((2930 - 60)! * 60!) computed using the combinations formula. Here, 2930 is the population size of ames$Gr.Liv.Area and 60 is the sample size. Two people sampling the exact same 60 houses would have a probability of 1 / m, an extremely small fraction. However, any two samples would share a similar distribution. Due to the Central Limit Theorem, an arbitrary sampling distribution would have a sample mean with an expected value of the population mean and a variance with an expected value of the population variance divided by the sample size. Since any two samples here would have the same size and are derived from the same population of data points, their distributions would be similar.

```{r, echo = TRUE, out.width = '55%'}

length(x = ames$Gr.Liv.Area)

```

## Confidence Intervals

One of the most common ways to describe the typical or central value of a distribution is to use the mean. In this case we can calculate the mean of the sample using,

```{r, echo = TRUE, out.width = '55%'}

sample_mean <- mean(samp)

```

Return for a moment to the question that first motivated this lab: based on this sample, what can we infer about the population? Based only on this single sample, the best estimate of the average living area of houses sold in Ames would be the sample mean, usually denoted as x¯ (here we're calling it sample_mean). That serves as a good point estimate but it would be useful to also communicate how uncertain we are of that estimate. This can be captured by using a confidence interval.

We can calculate a 95% confidence interval for a sample mean by adding and subtracting 1.96 standard errors to the point estimate.

```{r, echo = TRUE, out.width = '55%'}

se <- sd(samp) / sqrt(60)
lower <- sample_mean - 1.96 * se
upper <- sample_mean + 1.96 * se
c(lower, upper)

```
This is an important inference that we've just made: even though we don't know what the full population looks like, we're 95% confident that the true average size of houses in Ames lies between the values lower and upper. There are a few conditions that must be met for this interval to be valid.

Exercise 3: For the confidence interval to be valid, the sample mean must be normally distributed and have standard error s/√n. What conditions must be met for this to be true?

resp: The sample size n must be large enough. n = 1 would be a single data point with no variance, but the the formula for estimated population standard deviation (s/√n) would falsely output s, which would be 0. Since s is used in the numerator of the sample variance, this assumes that the population standard deviation is unknown and the sample variance is used as an estimate. Wheneverthe population variance (and thus standard deviation) is known, the population parameter is always used.

Exercise 4: What does "95% confidence" mean?

Resp: "95% confidence" means that 95% of confidence intervals (of the same correct size) constructed from all possible samples of the population would contain the population parameter. 

In this case we have the luxury of knowing the true population mean since we have data on the entire population. This value can be calculated using the following command:

```{r, echo = TRUE, out.width = '55%'}

mean(population)

```
Exercise 5: Does your confidence interval capture the true average size of houses in Ames?

Resp: Yes. Using the `contains` function, we can confirm that the previously constructed 95% confidence interval contains the population mean.

```{r, echo = TRUE, out.width = '55%'}

mean_pop <- mean(population)
cat("\npopulation mean: ", mean_pop)
cat("\npopulation mean contained in ci? ", contains(lower, upper, mean_pop))

```

Exercise 6: If you take a new sample every time the you get a slightly different confidence interval. What proportion of those intervals would you expect to capture the true population mean? Why?

Resp: 95%. That follows directly from the very definition of a 95% confidence interval.

Using R, we're going to recreate many samples to learn more about how sample means and confidence intervals vary from one sample to another. Loops come in handy here.

Here is the rough outline:

1. Obtain a random sample.
2. Calculate and store the sample's mean and standard deviation.
3. Repeat steps (1) and (2) 50 times.
4. Use these stored statistics to calculate many confidence intervals.

But before we do all of this, we need to first create empty vectors where we can save the means and standard deviations that will be calculated from each sample. And while we're at it, let's also store the desired sample size as n.


```{r, echo = TRUE, out.width = '55%'}

samp_mean <- rep(NA, 50)
samp_sd <- rep(NA, 50)
n <- 60

```

Now we're ready for the loop where we calculate the means and standard deviations of 50 random samples.

```{r, echo = TRUE, out.width = '55%'}

for(i in 1:50){
  # obtain a sample of size n = 60 from the population
  samp <- sample(population, n) 
  # save sample mean in ith element of samp_mean
  samp_mean[i] <- mean(samp) 
  # save sample sd in ith element of samp_sd
  samp_sd[i] <- sd(samp)        
}

```

Lastly, we construct the confidence intervals.

```{r, echo = TRUE, out.width = '55%'}

lower_vector <- samp_mean - 1.96 * samp_sd / sqrt(n) 
upper_vector <- samp_mean + 1.96 * samp_sd / sqrt(n)

```

Lower bounds of these 50 confidence intervals are stored in lower_vector, and the upper bounds are in upper_vector. Let's view the first interval.

```{r, echo = TRUE, out.width = '55%'}

c(lower_vector[1], upper_vector[1])

```

## On your own

1. Using the following function (which was downloaded with the data set), plot all intervals. What proportion of your confidence intervals include the true population mean? Is this proportion exactly equal to the confidence level? If not, explain why.

Resp: 2 / 50 are marked red for not containing the population mean μ. This means that 4% of CIs do not contain the μ and, by complement, 96% do contain μ. This is close to but not equal to 95% as expected. This is because 95% confidence indicates a probability, not a guarantee, of the proportion of n CIs independently generated would contain μ. As the number of samples taken (and CIs) increases, we expect the actual percentage of CIs to merge closer to the expected percentage confidence used.

```{r, echo = TRUE, out.width = '55%'}

require("plot_ci.R")

plot_ci(lower_vector, upper_vector, mean(population))

```

2. Pick a confidence level of your choosing, provided it is not 95%. What is the appropriate critical value?

Resp: When constructing a 99% CI, the critical value (gathered from Z-table) is 2.575.

3. Calculate 100 confidence intervals at the confidence level you chose in the previous question (following the outline above) for a sample size of n=100. Using the plot_ci function, plot all intervals and calculate the proportion of intervals that include the true population mean. How does this percentage compare to the confidence level selected for the intervals?

Resp: This CI with 99% confidence did not have any lines marked red, meaning all constructed CIs have contained μ. This performed with a higher percentage of CIs conatining μ than the previous 95% CI. Even after re-running the code several times, you may encounter a single red line on a rare occasion, which still outperforms the 95% CI. 

```{r, echo = TRUE, out.width = '55%'}

samp_mean <- rep(NA, 100)
samp_sd <- rep(NA, 100)
n <- 60

for(i in 1:100){
  # obtain a sample of size n = 60 from the population
  samp <- sample(population, n) 
  # save sample mean in ith element of samp_mean
  samp_mean[i] <- mean(samp) 
  # save sample sd in ith element of samp_sd
  samp_sd[i] <- sd(samp)        
}

lower_vector <- samp_mean - 2.575 * samp_sd / sqrt(n) 
upper_vector <- samp_mean + 2.575 * samp_sd / sqrt(n)

plot_ci(lower_vector, upper_vector, mean(population))

```

